import json
import chromadb
from chromadb.utils import embedding_functions
import os
import google.generativeai as genai
from dotenv import load_dotenv
from pathlib import Path
import time
from tqdm import tqdm

# 1. è¨­å®šç²¾æº–çš„è·¯å¾‘
current_dir = Path(__file__).parent 
root_dir = current_dir.parent
load_dotenv(root_dir / ".env")

DATA_PATH = current_dir / "data" / "laws.json"
DB_PATH = current_dir / "chroma_db"

def ingest_data():
    if not os.getenv("GOOGLE_API_KEY"):
        raise ValueError("âŒ æ‰¾ä¸åˆ° GOOGLE_API_KEY")
    if not DATA_PATH.exists():
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ³•å¾‹è³‡æ–™æª”ï¼š{DATA_PATH}")

    print(f"ğŸ“‚ æ­£åœ¨è®€å–è³‡æ–™ï¼š{DATA_PATH}")

    # åˆå§‹åŒ– ChromaDB
    client = chromadb.PersistentClient(path=str(DB_PATH))
    
    # è¨­å®š Gemini Embedding
    # âš ï¸ æ”¹ç”¨ text-embedding-004 æ¨¡å‹ï¼Œä¸¦æ˜ç¢ºæŒ‡å®š model_name
    google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(
        api_key=os.getenv("GOOGLE_API_KEY"),
        task_type="retrieval_document",
        model_name="models/text-embedding-004" 
    )

    collection = client.get_or_create_collection(
        name="legal_knowledge",
        embedding_function=google_ef
    )

    with open(DATA_PATH, "r", encoding="utf-8") as f:
        laws = json.load(f)

    print(f"ğŸ”„ æº–å‚™è™•ç† {len(laws)} æ¢æ³•è¦...")

    # --- âš™ï¸ èª¿æ•´åƒæ•¸å€ ---
    # æ¯æ¬¡åªè™•ç† 10 æ¢ (éå¸¸ä¿å®ˆï¼Œç¢ºä¿ä¸è¶…é Token é™åˆ¶)
    # é›–ç„¶æ…¢ï¼Œä½†ä¿è­‰èƒ½è·‘å®Œ
    BATCH_SIZE = 10 
    
    # ç¸½å…±éœ€è¦è·‘å¹¾æ‰¹
    total_batches = (len(laws) + BATCH_SIZE - 1) // BATCH_SIZE

    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦
    with tqdm(total=len(laws), desc="å¯«å…¥è³‡æ–™åº«") as pbar:
        i = 0
        while i < len(laws):
            batch = laws[i : i + BATCH_SIZE]
            
            documents = []
            ids = []
            metadatas = []

            for law in batch:
                documents.append(law["text"])
                ids.append(law["id"])
                metadatas.append({
                    "source": "law_db", 
                    "category": law.get("category", "unknown")
                })

            if not documents:
                break

            # --- ğŸ›¡ï¸ ç„¡é™é‡è©¦æ©Ÿåˆ¶ ---
            while True:
                try:
                    collection.upsert(
                        documents=documents,
                        ids=ids,
                        metadatas=metadatas
                    )
                    # æˆåŠŸäº†ï¼
                    # æ¯æ¬¡æˆåŠŸå¾Œä¼‘æ¯ 1 ç§’
                    time.sleep(1) 
                    
                    # æ›´æ–°é€²åº¦æ¢ä¸¦è·³å‡ºé‡è©¦è¿´åœˆ
                    pbar.update(len(batch))
                    break 

                except Exception as e:
                    error_msg = str(e)
                    if "429" in error_msg or "Quota exceeded" in error_msg:
                        print(f"\nâš ï¸ è§¸ç™¼é€Ÿç‡é™åˆ¶ (Rate Limit)ï¼Œæš«åœ 60 ç§’å†·å»ä¸­...")
                        # é‡åˆ° 429 éŒ¯èª¤ï¼Œå¼·åˆ¶ä¼‘æ¯ 60 ç§’
                        for _ in range(60):
                            time.sleep(1)
                        print("â™»ï¸ æ¢å¾©åŸ·è¡Œï¼Œæ­£åœ¨é‡è©¦...")
                        # é€™è£¡ä¸ breakï¼Œæœƒå›åˆ° while True é–‹é ­é‡è©¦
                    else:
                        print(f"\nâŒ ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ (è·³éæ­¤æ‰¹): {e}")
                        # å¦‚æœæ˜¯å…¶ä»–éŒ¯èª¤ï¼Œå°±è·³éé€™ä¸€æ‰¹ï¼Œé¿å…å¡æ­»
                        break 
            
            # ç§»å‹•åˆ°ä¸‹ä¸€æ‰¹
            i += BATCH_SIZE

    print(f"\nâœ… æˆåŠŸå°‡æ‰€æœ‰æ³•è¦å¯«å…¥å‘é‡è³‡æ–™åº«ï¼")
    print(f"ğŸ’¾ è³‡æ–™åº«å„²å­˜ä½ç½®ï¼š{DB_PATH}")

if __name__ == "__main__":
    # è‡ªå‹•å®‰è£ tqdm
    try:
        from tqdm import tqdm
    except ImportError:
        os.system("pip install tqdm")
        from tqdm import tqdm

    ingest_data()