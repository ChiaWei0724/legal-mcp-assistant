import os
import json
import jieba
import sqlite3
import uuid
import re
import urllib.parse
from datetime import datetime
from rank_bm25 import BM25Okapi
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import chromadb
from chromadb.utils import embedding_functions
import google.generativeai as genai
from dotenv import load_dotenv
from pathlib import Path
from typing import List, Optional, Dict, Any

# --- 1. ç’°å¢ƒè¨­å®š ---
base_path = Path(__file__).parent.parent
load_dotenv(base_path / ".env")

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("âŒ æ‰¾ä¸åˆ° GOOGLE_API_KEY")

genai.configure(api_key=GOOGLE_API_KEY)

# --- 2. åˆå§‹åŒ– SQLite è³‡æ–™åº« ---
DB_FILE = base_path / "backend" / "chat_history.db"

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS sessions
                 (id TEXT PRIMARY KEY, client_id TEXT, title TEXT, created_at TIMESTAMP, last_analysis TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS messages
                 (id INTEGER PRIMARY KEY AUTOINCREMENT, session_id TEXT, role TEXT, content TEXT, created_at TIMESTAMP)''')
    conn.commit()
    conn.close()

init_db()

# --- 3. åˆå§‹åŒ– ChromaDB ---
current_dir = Path(__file__).parent
DB_PATH = current_dir / "chroma_db"
client = chromadb.PersistentClient(path=str(DB_PATH))

google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(
    api_key=GOOGLE_API_KEY,
    model_name="models/text-embedding-004",
    task_type="retrieval_query"
)

try:
    collection = client.get_collection(name="legal_knowledge", embedding_function=google_ef)
    print(f"âœ… å‘é‡è³‡æ–™åº«é€£ç·šæˆåŠŸï¼ŒåŒ…å« {collection.count()} æ¢æ³•è¦")
except Exception as e:
    print(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
    collection = client.get_or_create_collection(name="legal_knowledge", embedding_function=google_ef)

# --- 4. åˆå§‹åŒ– BM25 ---
print("â³ æ­£åœ¨è¼‰å…¥ BM25 ç´¢å¼•...")
DATA_PATH = current_dir / "data" / "laws.json"
all_laws = []
bm25 = None

if DATA_PATH.exists():
    with open(DATA_PATH, "r", encoding="utf-8") as f:
        all_laws = json.load(f)
    tokenized_corpus = [list(jieba.cut(doc['text'])) for doc in all_laws]
    bm25 = BM25Okapi(tokenized_corpus)
else:
    print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° laws.json")

# --- 5. FastAPI è¨­å®š ---
app = FastAPI(title="Legal AI Assistant API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str
    style: str = "general"
    session_id: Optional[str] = None
    client_id: str

class CreateSessionRequest(BaseModel):
    client_id: str

# --- æ ¸å¿ƒåŠŸèƒ½ ---
def expand_synonyms(query: str) -> str:
    synonyms = {
        "é…’æ¸¬": "é…’ç²¾æ¿ƒåº¦ æ¸¬è©¦ æª¢å®š æ‹’çµ•",
        "ä¹ç­–": "é…’ç²¾æ¿ƒåº¦ æ¸¬è©¦ æª¢å®š æ‹’çµ•",
        "é—–ç´…ç‡ˆ": "è™ŸèªŒ ç®¡åˆ¶ é—–è¶Š äº¤å²”è·¯å£",
        "ç´…ç‡ˆ": "è™ŸèªŒ ç®¡åˆ¶",
        "è¶…é€Ÿ": "è¡Œè»Šé€Ÿåº¦ è¶…é æœ€é«˜æ™‚é€Ÿ",
        "ç„¡ç…§": "æœªé ˜æœ‰ é§•é§›åŸ·ç…§",
        "æœªç¦®è®“": "æš«åœ è®“ è¡Œäºº å…ˆè¡Œ",
        "å®‰å…¨å¸½": "æœªä¾è¦å®š æˆ´å®‰å…¨å¸½",
        "è‚‡é€ƒ": "ç™¼ç”Ÿäº¤é€šäº‹æ•… è‡´äººå‚·å®³ é€ƒé€¸",
        "è»Šç¦": "äº¤é€šäº‹æ•… æå®³è³ å„Ÿ",
        "æ’æ­»": "éå¤±è‡´æ­»",
        "æ’å‚·": "éå¤±å‚·å®³",
        "å·æ‹¿": "ç«Šç›œ ç«Šå– å‹•ç”¢",
        "å·æ±è¥¿": "ç«Šç›œ ç«Šå–",
        "æ¶": "æ¶å¥ª å¼·ç›œ",
        "æ‰“äºº": "å‚·å®³ç½ª èº«é«” å¥åº·",
        "ç½µäºº": "å…¬ç„¶ä¾®è¾± èª¹è¬— åè­½",
        "æåš‡": "åŠ å®³ ç”Ÿå‘½ èº«é«” è‡ªç”±",
        "é¨™éŒ¢": "è©æ¬º æ„åœ– ä¸æ³•æ‰€æœ‰",
        "æ®º": "æ®ºäºº ç”Ÿå‘½ å‚·å®³ è‡´æ­»",
        "æ®ºäºº": "åˆ‘æ³•ç¬¬271æ¢ ç”Ÿå‘½",
        "æ¬ éŒ¢": "å‚µå‹™ æ¸…å„Ÿ å€Ÿè²¸",
        "è³´å¸³": "å‚µå‹™ä¸å±¥è¡Œ",
        "è³ éŒ¢": "æå®³è³ å„Ÿ",
        "å™ªéŸ³": "å–§å›‚ æŒ¯å‹• å¦¨å®³å®‰å¯§",
        "åµ": "å–§å›‚ å¦¨å®³å®‰å¯§",
        "æ¨“ä¸Š": "è¿‘é„° åœŸåœ°æ‰€æœ‰äºº",
        "ç¸½çµ±": "å…¬å‹™å“¡ åœ‹å®¶å…ƒé¦– å…§äº‚ å¤–æ‚£",
        "åäºº": "å…¬çœ¾äººç‰© åè­½",
        "æ­Œæ‰‹": "å…¬çœ¾äººç‰©",
        "æ¼”å“¡": "å…¬çœ¾äººç‰©",
    }
    expanded = query
    for key, value in synonyms.items():
        if key in query:
            expanded += f" {value}"
    return expanded

def hybrid_search(query: str):
    expanded_query = expand_synonyms(query)
    print(f"ğŸ” æ“´å±•å¾Œæœå°‹è©: {expanded_query}")
    
    final_docs = []
    seen_ids = set()
    
    # 1. BM25 é—œéµå­—æœå°‹ (ç¯„åœæ“´å¤§è‡³ 50)
    if bm25:
        tokenized_query = list(jieba.cut(expanded_query))
        bm25_results = bm25.get_top_n(tokenized_query, all_laws, n=50)
        for doc in bm25_results:
            if doc['id'] not in seen_ids:
                final_docs.append({"text": doc['text'], "id": doc['id'], "score": 0.8})
                seen_ids.add(doc['id'])

    # 2. å‘é‡èªæ„æœå°‹ (ç¯„åœæ“´å¤§è‡³ 50)
    vector_results = collection.query(query_texts=[expanded_query], n_results=50)
    
    if vector_results['documents'] and vector_results['documents'][0]:
        for i, doc_text in enumerate(vector_results['documents'][0]):
            doc_id = vector_results['ids'][0][i]
            if doc_id not in seen_ids:
                final_docs.append({"text": doc_text, "id": doc_id, "score": 0.7})
                seen_ids.add(doc_id)
            else:
                for item in final_docs:
                    if item['id'] == doc_id:
                        item['score'] += 0.5

    # 3. é—œéµå­—åŠ æ¬Š
    keywords = list(jieba.cut(query))
    for item in final_docs:
        for kw in keywords:
            if len(kw) > 1 and kw in item['text']:
                item['score'] += 0.3

    final_docs.sort(key=lambda x: x['score'], reverse=True)
    return "\n\n".join([item['text'] for item in final_docs[:30]])

def query_gemini_rag(
    user_question: str,
    style: str,
    history: Optional[List[Dict[str, Any]]] = None,
):
    print(f"ğŸ‘¤ ä½¿ç”¨è€…: {user_question} | æ¨¡å¼: {style}")

    # 1. æ•´ç†æ­·å²ç´€éŒ„
    history = history or []
    recent_history = history[-10:]
    history_lines = []
    for msg in recent_history:
        role_name = "ä½¿ç”¨è€…" if msg['role'] == 'user' else "AIåŠ©æ‰‹"
        history_lines.append(f"{role_name}: {msg['content']}")
    history_text = "\n".join(history_lines) if history_lines else "ï¼ˆç„¡å¯åƒè€ƒçš„æ­·å²è¨Šæ¯ï¼‰"

    # 2. æœå°‹ RAG
    rewrite_model = genai.GenerativeModel('gemini-2.0-flash')
    try:
        rewrite_prompt = f"è«‹åƒè€ƒæ­·å²ï¼Œå°‡ä½¿ç”¨è€…å•é¡Œæ”¹å¯«ç‚ºç²¾æº–æ³•å¾‹æœå°‹å­—ä¸²ã€‚æ­·å²:{history_text} å•é¡Œ:{user_question} åªè¼¸å‡ºå­—ä¸²ã€‚"
        rewritten_query = rewrite_model.generate_content(rewrite_prompt).text.strip()
    except:
        rewritten_query = user_question

    context_text = hybrid_search(rewritten_query)
    if not context_text: context_text = "ï¼ˆè³‡æ–™åº«ä¸­æœªæ‰¾åˆ°ç›´æ¥ç›¸é—œæ³•æ¢ï¼‰"
    
    system_role = "ä½ æ˜¯ä¸€ä½å°ç£æ³•å¾‹ AI é¡§å•ã€‚ä½ çš„è·è²¬æ˜¯åƒ…å›ç­”èˆ‡ã€å°ç£æ³•å¾‹ã€‘ç›¸é—œçš„å•é¡Œã€‚å¦‚æœä½¿ç”¨è€…çš„å•é¡Œå®Œå…¨èˆ‡æ³•å¾‹ç„¡é—œï¼ˆä¾‹å¦‚ï¼šæ—©é¤åƒä»€éº¼ã€æ—…éŠæ¨è–¦ã€å¿ƒæƒ…é–’èŠï¼‰ï¼Œè«‹ç¦®è²Œæ‹’çµ•å›ç­”ï¼Œä¸¦å¼•å°ä½¿ç”¨è€…è©¢å•æ³•å¾‹ç›¸é—œå•é¡Œã€‚"
    
    reference_section_title = "ã€åƒè€ƒè³‡æ–™ã€‘"

    # 3. è¨­å®šæ¨¡å¼èˆ‡èªæ°£
    tone_instruction = ""
    case_instruction = ""  
    advice_instruction = "" 
    
    if style == "professional":
        tone_instruction = "èªæ°£åš´è‚…ã€å®¢è§€ã€ç²¾æº–ï¼Œä½¿ç”¨æ³•å¾‹å°ˆç”¨è¡“èªï¼Œç¨±å‘¼ä½¿ç”¨è€…ç‚ºã€ç•¶äº‹äººã€ã€‚"
        case_instruction = "è«‹å¼•ç”¨ä¸€å€‹ã€é¡ä¼¼çš„å¯¦å‹™åˆ¤æ±ºæ¡ˆä¾‹ã€‘ï¼ˆéœ€è™›æ§‹æ¡ˆè™Ÿå¦‚ï¼šè‡ºåŒ—åœ°é™¢112å¹´åº¦è¨´å­—ç¬¬Xè™Ÿï¼‰ï¼Œç°¡è¿°æ¡ˆæƒ…èˆ‡æ³•å®˜åˆ¤æ±ºé‚è¼¯ã€‚"
        advice_instruction = "è«‹åˆ—å‡º 3 é»ã€è¨´è¨Ÿæ”»é˜²å»ºè­°ã€‘ï¼Œä¾‹å¦‚è­‰æ“šä¿å…¨é‡é»ã€ä¸»å¼µæ³•æ¢ä¾æ“šã€‚"
    elif style == "humorous":
        tone_instruction = "èªæ°£éå¸¸å¹½é»˜ã€å……æ»¿é„‰æ°‘æ¢—ã€ä½¿ç”¨èª‡å¼µçš„æ¯”å–»ï¼ˆå¦‚ï¼šæ¯”æ‚²å‚·æ›´æ‚²å‚·çš„æ•…äº‹ï¼‰ã€‚"
        case_instruction = "è«‹ç·¨å¯«ä¸€å€‹ã€è’è¬¬å¥½ç¬‘çš„æ¨¡æ“¬æƒ…å¢ƒã€‘ï¼ˆä¾‹å¦‚ï¼šå°æ˜é¨å±±è±¬æ’åˆ°å¤–æ˜Ÿäºº...ï¼‰ï¼Œç”¨é€™å€‹æ•…äº‹ä¾†å¸¶å‡ºæ³•å¾‹å¾Œæœã€‚"
        advice_instruction = "è«‹åˆ—å‡º 3 é»ã€ä¸æƒ³è¢«æŠ“å»é—œçš„å¯¦å‹™å»ºè­°ã€‘ï¼Œé›–ç„¶èªæ°£å¥½ç¬‘ä½†å…§å®¹å¿…é ˆå¯¦ç”¨ã€‚"
    else: 
        tone_instruction = "èªæ°£è¦ªåˆ‡ç™½è©±ï¼Œåƒé„°å±…å¤§å“¥å“¥/å¤§å§Šå§Šï¼Œå®Œå…¨ä¸ç”¨è‰±æ·±è¡“èªã€‚"
        case_instruction = "è«‹èˆ‰ä¸€å€‹ã€ç”Ÿæ´»å¸¸è¦‹ä¾‹å­ã€‘ï¼ˆä¾‹å¦‚ï¼šåœ¨å··å£æ“¦æ’æ©Ÿè»Š...ï¼‰ä¾†èªªæ˜ã€‚"
        advice_instruction = "è«‹åˆ—å‡º 3 é»ã€ç•¶ä¸‹SOPã€‘ï¼Œæ•™ä½¿ç”¨è€…ç¬¬ä¸€æ™‚é–“è©²åšä»€éº¼ã€‚"

    # 4. çµ„åˆæœ€çµ‚ Prompt
    final_prompt = f"""
    {system_role}
    èªæ°£è¦æ±‚ï¼š{tone_instruction}
    
    {reference_section_title}ï¼ˆè«‹åš´æ ¼åŸºæ–¼æ­¤å…§å®¹å›ç­”ï¼Œè‹¥ç„¡ç›¸é—œå…§å®¹è«‹å‹¿ç·¨é€ ï¼‰ï¼š
    {context_text}
    
    ã€æ­·å²å°è©±åƒè€ƒã€‘ï¼š
    {history_text}
    
    ã€ä½¿ç”¨è€…å•é¡Œã€‘ï¼š
    {user_question} (AIç†è§£: {rewritten_query})
    
    ã€å›ç­”æ ¼å¼è¦æ±‚ (è«‹åš´æ ¼éµå®ˆç« ç¯€é †åº)ã€‘ï¼š
    1. **çµè«–å…ˆè¡Œ**ï¼šç¬¬ä¸€å¥è©±ç›´æ¥å›ç­”æ ¸å¿ƒçµæœï¼ˆç½°å¤šå°‘éŒ¢ï¼Ÿåˆ‘è²¬ç‚ºä½•ï¼Ÿï¼‰ã€‚
    2. **æƒ…å¢ƒæ¡ˆä¾‹**ï¼š{case_instruction}
    3. **è©³ç´°åˆ†æ**ï¼šä¾æ“šæ³•æ¢é€²è¡Œåˆ†æã€‚
       - è‹¥ä½¿ç”¨è€…è©¢å•ç‰¹å®šèº«åˆ†ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºæ³•å¾‹ä¹‹å‰äººäººå¹³ç­‰ï¼Œç›´æ¥å¼•ç”¨ä¸€èˆ¬æ³•æ¢é€²è¡Œèªªæ˜ã€‚
    4. **å¯¦å‹™å»ºè­°**ï¼š{advice_instruction} (é€™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼Œè«‹å‹™å¿…åˆ—é»èªªæ˜)ã€‚
    5. **æ³•å¾‹ä¾æ“š**ï¼š
       - å¼•ç”¨æ³•æ¢æ ¼å¼ï¼š `[**æ³•è¦åç¨±ç¬¬Xæ¢**](law://content/æ¢æ–‡å…§å®¹)`
       - **çµ•å°ç¦æ­¢**ï¼šç¦æ­¢ AI è‡ªè¡Œç·¨é€ é€£çµå…§çš„æ¢æ–‡å…§å®¹ã€‚
       - **å¼·åˆ¶è¦å‰‡**ï¼šå°æ‹¬è™Ÿå…§çš„ `law://content/` å¾Œé¢ï¼Œ**å¿…é ˆ** æ˜¯ä¾†è‡ªä¸Šè¿° {reference_section_title} ä¸­è©²æ³•æ¢çš„å®Œæ•´åŸæ–‡ã€‚
       - **ç¼ºæ¼è™•ç†**ï¼šè‹¥åƒè€ƒè³‡æ–™ä¸­æ²’æœ‰è©²æ¢æ–‡å®Œæ•´å…§å®¹ï¼Œè«‹å¡«å¯« `law://content/ç„¡å®Œæ•´æ¢æ–‡å…§å®¹`ï¼Œä½†**ä¸­æ‹¬è™Ÿå…§ä»é ˆå¯«å‡ºæ­£ç¢ºçš„æ¢è™Ÿ**ã€‚

    ã€å¼·åˆ¶è¦æ±‚ï¼šæœ€æœ«è¡Œè¼¸å‡º JSON å€å¡Šã€‘
    - å›è¦†çš„æœ€å¾Œä¸€æ®µå¿…é ˆå®Œå…¨ç¬¦åˆä»¥ä¸‹æ ¼å¼ï¼š
      ---JSON_START---
      {{
          "domain": "æ¶‰åŠæ³•å¾‹é ˜åŸŸ",
          "risk_level": "é¢¨éšªç­‰ç´š",
          "keywords": ["é—œéµå­—1", "é—œéµå­—2"]
      }}
      ---JSON_END---
    """

    answer_model = genai.GenerativeModel('gemini-2.0-flash')
    response_text = answer_model.generate_content(final_prompt).text

    # 5. è§£æ JSON èˆ‡å…§å®¹
    reply_content = response_text
    analysis_data = {"domain": "åˆ†æä¸­", "risk_level": "æœªçŸ¥", "keywords": []}

    json_match = re.search(r"---JSON_START---(.*?)---JSON_END---", response_text, re.DOTALL)
    if json_match:
        json_block = json_match.group(1).strip()
        try:
            analysis_data = json.loads(json_block)
        except json.JSONDecodeError:
            pass
        # ç§»é™¤ JSON å€å¡Š
        reply_content = response_text[:json_match.start()].strip()
            
    # 6. æ³•æ¢é€£çµè™•ç† (â˜…é—œéµï¼šä½¿ç”¨ quote ç·¨ç¢¼è§£æ±º Markdown ç©ºæ ¼å•é¡Œâ˜…)
    law_pattern = re.compile(r'\[(?P<text>[^\]]+)\]\s*\((?P<link>law://content/[^)]+)\)')

    def encode_law(match: re.Match) -> str:
        text = match.group("text")
        link = match.group("link")
        
        raw_content = link.replace("law://content/", "", 1)
        
        try:
            decoded_first = urllib.parse.unquote(raw_content)
        except:
            decoded_first = raw_content

        if decoded_first == "ç„¡å®Œæ•´æ¢æ–‡å…§å®¹":
            return f"[{text}](law://content/æš«ç„¡æ­¤æ¢æ–‡çš„å®Œæ•´å…§å®¹ï¼Œè«‹é»æ“Šé€£çµå‰å¾€å…¨åœ‹æ³•è¦è³‡æ–™åº«æŸ¥è©¢ã€‚)"

        # ç§»é™¤æ›è¡Œç¬¦è™Ÿ
        safe_content = decoded_first.replace("\n", "").replace("\r", "")
        
        # â˜… é—œéµï¼šå¼·åˆ¶ URL Encodeï¼Œé€™æ¨£ç©ºæ ¼æœƒè®Šæˆ %20ï¼Œæ‹¬è™Ÿè®Šæˆ %28ï¼ŒMarkdown å°±æœƒä¹–ä¹–è§£ææˆé€£çµ
        final_encoded = urllib.parse.quote(safe_content)
        
        return f"[{text}](law://content/{final_encoded})"

    reply_content = law_pattern.sub(encode_law, reply_content)

    # 7. æœ€çµ‚è™•ç†ï¼šå¼·åˆ¶çµ±ä¸€å…è²¬è²æ˜
    reply_content = reply_content.replace("> æœ¬å›è¦†åƒ…ä¾›åƒè€ƒï¼Œä¸ä»£è¡¨æ­£å¼æ³•å¾‹æ„è¦‹ã€‚å¯¦éš›å€‹æ¡ˆè«‹è«®è©¢å°ˆæ¥­å¾‹å¸«ã€‚", "")
    reply_content = reply_content.replace("æœ¬å›è¦†åƒ…ä¾›åƒè€ƒï¼Œä¸ä»£è¡¨æ­£å¼æ³•å¾‹æ„è¦‹ã€‚å¯¦éš›å€‹æ¡ˆè«‹è«®è©¢å°ˆæ¥­å¾‹å¸«ã€‚", "")
    reply_content = reply_content.strip()

    disclaimer = "\n\n> æœ¬å›è¦†åƒ…ä¾›åƒè€ƒï¼Œä¸ä»£è¡¨æ­£å¼æ³•å¾‹æ„è¦‹ã€‚å¯¦éš›å€‹æ¡ˆè«‹è«®è©¢å°ˆæ¥­å¾‹å¸«ã€‚"
    reply_content += disclaimer

    return {"reply": reply_content, "analysis": analysis_data}

# --- API è·¯ç”± ---
@app.get("/")
def read_root(): return {"message": "Legal AI Backend Running"}

@app.get("/sessions")
def get_sessions(client_id: str = Query(..., description="ä½¿ç”¨è€…çš„å”¯ä¸€ ID")):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT id, title, created_at FROM sessions WHERE client_id = ? ORDER BY created_at DESC", (client_id,))
    sessions = [{"id": row[0], "title": row[1], "created_at": row[2]} for row in c.fetchall()]
    conn.close()
    return sessions

@app.post("/sessions")
def create_session(request: CreateSessionRequest):
    session_id = str(uuid.uuid4())
    created_at = datetime.now().isoformat()
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT INTO sessions (id, client_id, title, created_at, last_analysis) VALUES (?, ?, ?, ?, ?)", 
              (session_id, request.client_id, "æ–°å°è©±", created_at, "{}"))
    conn.commit()
    conn.close()
    return {"id": session_id, "title": "æ–°å°è©±"}

@app.delete("/sessions/{session_id}")
def delete_session(session_id: str):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("DELETE FROM sessions WHERE id = ?", (session_id,))
    c.execute("DELETE FROM messages WHERE session_id = ?", (session_id,))
    conn.commit()
    conn.close()
    return {"status": "deleted", "id": session_id}

@app.get("/sessions/{session_id}")
def get_session_messages(session_id: str):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT role, content FROM messages WHERE session_id = ? ORDER BY id ASC", (session_id,))
    messages = [{"role": row[0], "content": row[1]} for row in c.fetchall()]
    c.execute("SELECT last_analysis FROM sessions WHERE id = ?", (session_id,))
    row = c.fetchone()
    analysis = json.loads(row[0]) if row and row[0] else None
    conn.close()
    return {"messages": messages, "analysis": analysis}

@app.post("/chat")
async def chat(request: ChatRequest):
    session_id = request.session_id
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    
    if not session_id:
        session_id = str(uuid.uuid4())
        created_at = datetime.now().isoformat()
        title = request.message[:10]
        c.execute("INSERT INTO sessions (id, client_id, title, created_at, last_analysis) VALUES (?, ?, ?, ?, ?)", 
                  (session_id, request.client_id, title, created_at, "{}"))
    
    # è®€å–æœ€è¿‘ 10 å‰‡æ­·å²ç´€éŒ„
    c.execute(
        "SELECT role, content FROM messages WHERE session_id = ? ORDER BY id DESC LIMIT 10",
        (session_id,)
    )
    rows = c.fetchall()
    history = [{"role": row[0], "content": row[1]} for row in reversed(rows)]
    
    try:
        # å‘¼å« query_gemini_rag
        result = query_gemini_rag(request.message, request.style, history)
        
        ai_reply = result["reply"]
        analysis_data = result["analysis"]
        
        # å¯«å…¥è¨Šæ¯
        now = datetime.now().isoformat()
        c.execute("INSERT INTO messages (session_id, role, content, created_at) VALUES (?, ?, ?, ?)", (session_id, "user", request.message, now))
        c.execute("INSERT INTO messages (session_id, role, content, created_at) VALUES (?, ?, ?, ?)", (session_id, "assistant", ai_reply, now))
        
        # æ›´æ–°æœ€å¾Œåˆ†æçµæœ
        c.execute("UPDATE sessions SET last_analysis = ? WHERE id = ?", (json.dumps(analysis_data), session_id))
        
        conn.commit()
        
        return {"reply": ai_reply, "session_id": session_id, "analysis": analysis_data}
        
    except Exception as e:
        print(f"Error: {e}")
        return {
            "reply": "âŒ ç³»çµ±ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
            "session_id": session_id,
            "analysis": None
        }
    finally:
        conn.close()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)